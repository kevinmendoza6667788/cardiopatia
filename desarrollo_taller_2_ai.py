# -*- coding: utf-8 -*-
"""Desarrollo_Taller_2_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ewpNYpzn1GICNYxML-52EmtBseKmcwFC

#Integrantes:
- Gomez Mendoza Franklin Kevin
- Mendoza Huerto Frankling Augusto
- Pacheco Rodriguez Arnold

#Pasos para un proyecto de aprendizaje estadístico (Machine learning)
Este notebook se basa en el capítulo 2 y el apéndice 2 del libro Hands-On Machine learning with Scikit-Learn & Tensorflow de Aurélien Géron, pero adaptado a un problema "real" de clasificación.

Estas son los etapas básicas que se deben seguir al desarrollar un proyecto de aprendizaje estadístico (o machine learning):

1. Enmarcar el problema y observar el panorama general.
2. Obtener los datos.
3. Explorar y visualizar los datos para obtener información.
4. Preparar los datos para exponer mejor los patrones a los algoritmos de aprendizaje estadístico.
5. Explorar muchos modelos diferentes y seleccionar los mejores.
6. Poner a punto (fine-tune) esos modelos y si es posible combinarlos en una gran solución.
7. Presentar la solución, ¿Cual es la mejor solución?
8. Lanzar, monitorear y mantener el sistema implementado.

### Ejercicio

1. Mejore los resultados del Modelo propuesto, pruebe cambiar diferentes hiperparámetros, otros Learning Rates, más capas, etc. Grafique la matriz de confusión para el conjunto de test.

2. Vea este problema como uno de regresión (use MLPRegressor) tomando la variable de salida (la clase) como valor numérico (cera de 0 y 1). Al final defina la clase al calcular una sigmoide y luego con la probabilidad mayoritaria. Calcule métricas de regresión y clasificacion. ¿Es mejor, peor, por qué?

# 1. ¿Cúal es el problema?

## Heart Disease Data Set

https://archive.ics.uci.edu/ml/datasets/Heart+Disease


This database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, **the Cleveland database** is the only one that has been used by ML researchers to this date.  The "goal" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  
   
The names and social security numbers of the patients were recently removed from the database, replaced with dummy values.

One file has been "processed", that one containing the Cleveland database.  All four unprocessed files also exist in this directory.
    
5. Number of Instances:
        Database:    # of instances:
          Cleveland: 303
          Hungarian: 294
        Switzerland: 123
      Long Beach VA: 200

6. Number of Attributes: 76 (including the predicted attribute)

7. Attribute Information:

      -- Only 14 used
      
      -- 1. #3  (age)       
      -- 2. #4  (sex)       
      -- 3. #9  (cp)        
      -- 4. #10 (trestbps)  
      -- 5. #12 (chol)      
      -- 6. #16 (fbs)       
      -- 7. #19 (restecg)   
      -- 8. #32 (thalach)   
      -- 9. #38 (exang)     
      -- 10. #40 (oldpeak)   
      -- 11. #41 (slope)     
      -- 12. #44 (ca)        
      -- 13. #51 (thal)      
      -- 14. #58 (num)       (the predicted attribute)

Complete attribute documentation:

      1 id: patient identification number
      2 ccf: social security number (I replaced this with a dummy value of 0)
      3 age: age in years
      4 sex: sex (1 = male; 0 = female)
      5 painloc: chest pain location (1 = substernal; 0 = otherwise)
      6 painexer (1 = provoked by exertion; 0 = otherwise)
      7 relrest (1 = relieved after rest; 0 = otherwise)
      8 pncaden (sum of 5, 6, and 7)
      9 cp: chest pain type
        -- Value 1: typical angina
        -- Value 2: atypical angina
        -- Value 3: non-anginal pain
        -- Value 4: asymptomatic
     10 trestbps: resting blood pressure (in mm Hg on admission to the
        hospital)
     11 htn
     12 chol: serum cholestoral in mg/dl
     13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)
     14 cigs (cigarettes per day)
     15 years (number of years as a smoker)
     16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)
     17 dm (1 = history of diabetes; 0 = no such history)
     18 famhist: family history of coronary artery disease (1 = yes; 0 = no)
     19 restecg: resting electrocardiographic results
        -- Value 0: normal
        -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST
                    elevation or depression of > 0.05 mV)
        -- Value 2: showing probable or definite left ventricular hypertrophy
                    by Estes' criteria
     20 ekgmo (month of exercise ECG reading)
     21 ekgday(day of exercise ECG reading)
     22 ekgyr (year of exercise ECG reading)
     23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)
     24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)
     25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)
     26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)
     27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)
     28 proto: exercise protocol
          1 = Bruce     
          2 = Kottus
          3 = McHenry
          4 = fast Balke
          5 = Balke
          6 = Noughton
          7 = bike 150 kpa min/min  (Not sure if "kpa min/min" is what was
              written!)
          8 = bike 125 kpa min/min  
          9 = bike 100 kpa min/min
         10 = bike 75 kpa min/min
         11 = bike 50 kpa min/min
         12 = arm ergometer
     29 thaldur: duration of exercise test in minutes
     30 thaltime: time when ST measure depression was noted
     31 met: mets achieved
     32 thalach: maximum heart rate achieved
     33 thalrest: resting heart rate
     34 tpeakbps: peak exercise blood pressure (first of 2 parts)
     35 tpeakbpd: peak exercise blood pressure (second of 2 parts)
     36 dummy
     37 trestbpd: resting blood pressure
     38 exang: exercise induced angina (1 = yes; 0 = no)
     39 xhypo: (1 = yes; 0 = no)
     40 oldpeak = ST depression induced by exercise relative to rest
     41 slope: the slope of the peak exercise ST segment
        -- Value 1: upsloping
        -- Value 2: flat
        -- Value 3: downsloping
     42 rldv5: height at rest
     43 rldv5e: height at peak exercise
     44 ca: number of major vessels (0-3) colored by flourosopy
     45 restckm: irrelevant
     46 exerckm: irrelevant
     47 restef: rest raidonuclid (sp?) ejection fraction
     48 restwm: rest wall (sp?) motion abnormality
        0 = none
        1 = mild or moderate
        2 = moderate or severe
        3 = akinesis or dyskmem (sp?)
     49 exeref: exercise radinalid (sp?) ejection fraction
     50 exerwm: exercise wall (sp?) motion
     51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect
     52 thalsev: not used
     53 thalpul: not used
     54 earlobe: not used
     55 cmo: month of cardiac cath (sp?)  (perhaps "call")
     56 cday: day of cardiac cath (sp?)
     57 cyr: year of cardiac cath (sp?)
     58 num: diagnosis of heart disease (angiographic disease status)
        -- Value 0: < 50% diameter narrowing
        -- Value 1: > 50% diameter narrowing
        (in any major vessel: attributes 59 through 68 are vessels)
     59 lmt
     60 ladprox
     61 laddist
     62 diag
     63 cxmain
     64 ramus
     65 om1
     66 om2
     67 rcaprox
     68 rcadist
     69 lvx1: not used
     70 lvx2: not used
     71 lvx3: not used
     72 lvx4: not used
     73 lvf: not used
     74 cathef: not used
     75 junk: not used
     76 name: last name of patient
	(I replaced this with the dummy string "name")

9. Missing Attribute Values: Several.  Distinguished with value -9.0.

10. Class Distribution:
        Database:      0   1   2   3   4 Total
          Cleveland: 164  55  36  35  13   303
          Hungarian: 188  37  26  28  15   294
        Switzerland:   8  48  32  30   5   123
      Long Beach VA:  51  56  41  42  10   200


### Cleveland dataset


- *age*: age in years
- *sex*: (1 = male; 0 = female)
- *cp*: chest pain type
- *trestbps*: resting blood pressure (in mm Hg on admission: to the hospital)
- *chol*: serum cholestoral in mg/dl
- *fbs*: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)
- *restecg*: resting electrocardiographic results
- *thalach*: maximum heart rate achieved
- *exan*: gexercise induced angina (1 = yes; 0 = no)
- *oldpeak*: ST depression induced by exercise relative to rest
- *slope*: the slope of the peak exercise ST segment
- *ca*: number of major vessels (0-3) colored by flourosopy
- *thal*: 3 = normal; 6 = fixed defect; 7 = reversable defect
- *AHD*: angiographic disease status
    - Value 0: < 50% diameter narrowing
    - Value 1: > 50% diameter narrowing

**References**

[Detrano, Robert, et al. "International application of a new probability algorithm for the diagnosis of coronary artery disease." The American journal of cardiology 64.5 (1989): 304-310.](https://www.sciencedirect.com/science/article/pii/0002914989905249)

### Diccionario de variables del conjunto de datos de Enfermedad Cardíaca

- *Age*: Edad del paciente (en años)
- *Sex*: Sexo (1 = masculino, 0 = femenino)
- *ChestPain*: Tipo de dolor de pecho:  
  - *typical*: dolor típico de angina  
  - *atypical* o *nontypical*: dolor atípico  
  - *nonanginal*: dolor no anginoso  
  - *asymptomatic*: sin síntomas
- *RestBP*: Presión arterial en reposo (mm Hg)
- *Chol*: Colesterol sérico en mg/dl
- *Fbs*: Glucosa en ayunas > 120 mg/dl (1 = sí, 0 = no)
- *RestECG*: Resultados del electrocardiograma en reposo  
  - 0 = normal  
  - 1 = anormal leve  
  - 2 = probable o definitiva hipertrofia ventricular izquierda
- *MaxHR*: Frecuencia cardíaca máxima alcanzada
- *ExAng*: Angina inducida por ejercicio (1 = sí, 0 = no)
- *Oldpeak*: Depresión del segmento ST inducida por el ejercicio en comparación con el reposo
- *Slope*: Pendiente del segmento ST durante el ejercicio  
  - 1 = ascendente  
  - 2 = plana  
  - 3 = descendente
- *Ca*: Número de vasos principales coloreados por fluoroscopía (0–3)
- *Thal*: Tipo de talasemia  
  - *normal*  
  - *fixed*: defecto fijo  
  - *reversable*: defecto reversible
- *AHD*: Presencia de enfermedad cardíaca  
  - *Yes* = tiene enfermedad
"""


# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import warnings
warnings.filterwarnings('ignore')

df = pd.read_csv('/content/heart.csv', na_values='NA')
df.shape

df.head()

df.info()

df.dtypes

df.describe()

print(df.isnull().sum())
plt.figure(figsize=(10,5))
sns.heatmap(df.isnull(), cbar=False, cmap="coolwarm", yticklabels=False)
plt.title("Mapa de calor de valores nulos")
plt.show()

duplicados = df.duplicated().sum()
print(f"Filas duplicadas: {duplicados}")

for col in df.columns:
  print(f"{col}: {df[col].nunique()}")

print(df['AHD'].value_counts())
df['AHD']=df['AHD'].map({'No':0, 'Yes':1})

print(df[['Ca', 'Thal']].isnull().sum())

"""Como son pocos variables nulas son muy importantes para el diagnóstico cardiaco, no es recomendable eliminarlas, entonces lo imputamos."""

# Imputamos con la moda (valor más frecuente)
df['Ca']=df['Ca'].fillna(df['Ca'].mode()[0])
df['Thal']=df['Thal'].fillna(df['Thal'].mode()[0])

df.isnull().sum()

"""###  EXPLORACIÓN Y VISUALIZACIÓN DE LOS DATOS"""

df.describe().T

# Verificar si hay alguna columna Unnamed
df.columns = df.columns.str.strip()  # elimina espacios accidentales
unnamed_cols = [col for col in df.columns if "Unnamed" in col]

# Eliminar columna 'Unnamed'ya que no aporta valor
if unnamed_cols:
    df.drop(columns=unnamed_cols, inplace=True)
    print(f"Columnas eliminadas: {unnamed_cols}")
else:
    print("No se encontraron columnas 'Unnamed'.")

numeric_cols=df.select_dtypes(include='number').columns.to_list()

for col in numeric_cols:
  plt.figure(figsize=(8,4))
  sns.histplot(df[col], kde=True, bins=30, color='dodgerblue')
  plt.title(f'Distribución de {col}')
  plt.xlabel(col)
  plt.ylabel('Frecuencia')
  plt.grid(True)
  plt.tight_layout()
  plt.show()

categoricas_cols=df.select_dtypes(include='object').columns.tolist()

for col in categoricas_cols:
  plt.figure(figsize=(6,4))
  sns.countplot(data=df, x=col, palette='viridis')
  plt.title(f'Conteo de {col}')
  plt.xticks(rotation=45)
  plt.tight_layout()
  plt.show()

# 1. Edad vs AHD → Violinplot para comparar distribución por clases
sns.violinplot(x='AHD', y='Age',palette='Set1', data=df)
plt.title('Distribución de Edad según AHD')
plt.show()

# 2. Trestbps vs AHD → Boxplot para analizar diferencias en la mediana y outliers
sns.boxplot(x='AHD', y='RestBP',palette='Set1', data=df)
plt.title('Presión arterial en reposo vs AHD')
plt.show()

# 3. Colesterol vs AHD → Violinplot para visualizar distribución + outliers
sns.violinplot(x='AHD', y='Chol',palette='Set1',  data=df)
plt.title('Distribución de Colesterol según AHD')
plt.show()

# 4. Thalach vs AHD → KDE Plot: Compara formas de la distribución por clase
sns.kdeplot(data=df[df['AHD']==0]['MaxHR'], label='No AHD', fill=True)
sns.kdeplot(data=df[df['AHD']==1]['MaxHR'], label='AHD', fill=True)
plt.title('Distribución de Frecuencia Cardíaca Máxima (MaxHR)')
plt.legend()
plt.show()

# 5. Oldpeak vs AHD → Boxplot para analizar diferencias en depresión ST
sns.boxplot(x='AHD', y='Oldpeak', data=df)
plt.title('Depresión ST inducida por ejercicio vs AHD')
plt.show()

# 6. Sexo vs AHD → Countplot para ver cantidad de casos por género y clase
sns.countplot(x='Sex', hue='AHD', data=df)
plt.title('Distribución de AHD por Sexo (0: Mujer, 1: Hombre)')
plt.show()

# 7. Cp (Tipo de dolor en el pecho) vs AHD → Countplot porque hay pocos niveles
sns.countplot(x='ChestPain', hue='AHD', data=df)
plt.title('Tipo de dolor en el pecho vs AHD')
plt.show()

# 9. Thal (defecto cardíaco) vs AHD → Countplot por tratarse de categorías discretas
sns.countplot(x='Thal', hue='AHD', data=df)
plt.title('Defecto detectado (Thal) vs AHD')
plt.show()

# 10. Ca (vasos coloreados) vs AHD → Countplot para analizar impacto de número de vasos
sns.countplot(x='Ca', hue='AHD', data=df)
plt.title('Número de vasos coloreados vs AHD')
plt.show()

plt.figure(figsize=(12, 10))
sns.heatmap(df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Matriz de Correlación entre Variables Numéricas')
plt.show()

plt.figure(figsize=(5, 4))
sns.countplot(x='AHD', data=df, palette='cool')
plt.title('Distribución de la Variable AHD')
plt.xlabel('Presencia de Enfermedad Cardíaca (0 = No, 1 = Sí)')
plt.ylabel('Conteo')
plt.show()

print(df['AHD'].value_counts(normalize=True))

"""### 4. Preparar datos"""

print(df.dtypes)

"""Convertir categóricas a numéricas"""

from sklearn.preprocessing import LabelEncoder

df['ChestPain'] = LabelEncoder().fit_transform(df['ChestPain'])
df.dtypes

# Convert 'Thal' column to string type before applying LabelEncoder
df['Thal'] = df['Thal'].astype(str)
df['Thal'] = LabelEncoder().fit_transform(df['Thal'])
df.dtypes

df.head()

"""Separamos la variable objetivo y escalamos las variables predictores "x"
"""

from sklearn.preprocessing import StandardScaler

# Separar X e Y
X = df.drop('AHD', axis=1)
y = df['AHD']

# Escalado
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Volver a DataFrame si se quiere conservar nombres de columnas
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

"""Dividimos el conjunto de datos en entrenamiento y prueba"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y)

"""### 5. Explorar muchos modelos diferentes y seleccionar los mejores"""

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB

from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

modelos = { 'Regresión Logística': LogisticRegression(max_iter=1000, random_state=42),
            'KNN': KNeighborsClassifier(), 'SVM': SVC(probability=True),
            'Árbol de Decisión': DecisionTreeClassifier(random_state=42),
            'Random Forest': RandomForestClassifier(random_state=42),
            'Gradient Boosting': GradientBoostingClassifier(random_state=42),
            'Naive Bayes': GaussianNB() }

resultados = {}

# Entrenamiento y evaluación de cada modelo
for nombre, modelo in modelos.items():
    print(f"\n Entrenando modelo: {nombre}")
    try:
        # Entrenamiento del modelo
        modelo.fit(X_train, y_train)

        # Predicciones sobre el conjunto de prueba
        y_pred = modelo.predict(X_test)

        # Métricas de evaluación
        acc = accuracy_score(y_test, y_pred)
        cv = cross_val_score(modelo, X_train, y_train, cv=5).mean()
        cm = confusion_matrix(y_test, y_pred)
        cr = classification_report(y_test, y_pred, output_dict=True)

        # Resultados en el diccionario
        resultados[nombre] = {
            'Accuracy': acc,
            'CV Accuracy': cv,
            'Precision (Clase 1)': cr['1']['precision'],
            'Recall (Clase 1)': cr['1']['recall'],
            'F1-score (Clase 1)': cr['1']['f1-score'],
            'Matriz de Confusión': cm
        }

    except Exception as e:
        print(f" Error al entrenar el modelo {nombre}: {e}")

resultados_df = pd.DataFrame(resultados).T

resultados_df = resultados_df.sort_values(by='Recall (Clase 1)', ascending=False)

print("Resumen de modelos:")
display(resultados_df[['Accuracy', 'CV Accuracy', 'Precision (Clase 1)', 'Recall (Clase 1)', 'F1-score (Clase 1)']])

fig, axes = plt.subplots(1, 5, figsize=(24, 5))

# Accuracy
sns.barplot(x=resultados_df.index, y='Accuracy', data=resultados_df, ax=axes[0], palette='coolwarm')
axes[0].set_title('Accuracy por Modelo')
axes[0].tick_params(axis='x', rotation=45)

# CV Accuracy
sns.barplot(x=resultados_df.index, y='CV Accuracy', data=resultados_df, ax=axes[1], palette='cubehelix')
axes[1].set_title('CV Accuracy por Modelo')
axes[1].tick_params(axis='x', rotation=45)

# Precision (Clase 1)
sns.barplot(x=resultados_df.index, y='Precision (Clase 1)', data=resultados_df, ax=axes[2], palette='BuPu')
axes[2].set_title('Precision (Clase 1) por Modelo')
axes[2].tick_params(axis='x', rotation=45)

# Recall (Clase 1)
sns.barplot(x=resultados_df.index, y='Recall (Clase 1)', data=resultados_df, ax=axes[3], palette='viridis')
axes[3].set_title('Recall (Clase 1) por Modelo')
axes[3].tick_params(axis='x', rotation=45)

# F1-score (Clase 1)
sns.barplot(x=resultados_df.index, y='F1-score (Clase 1)', data=resultados_df, ax=axes[4], palette='magma')
axes[4].set_title('F1-score (Clase 1) por Modelo')
axes[4].tick_params(axis='x', rotation=45)

plt.suptitle("Comparación de Métricas por Modelo", fontsize=16)
plt.tight_layout()
plt.show()

print("Matrices de Confusión de todos los modelos:\n")

fig, axes = plt.subplots(3, 3, figsize=(16, 14))
axes = axes.flatten()

for idx, (nombre, datos) in enumerate(resultados.items()):
    cm = datos['Matriz de Confusión']
    sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu', ax=axes[idx])
    axes[idx].set_title(f'{nombre}')
    axes[idx].set_xlabel('Predicción')
    axes[idx].set_ylabel('Real')

# Quitar ejes vacíos si hay menos de 9 modelos
for j in range(idx + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.suptitle("Matrices de Confusión de Todos los Modelos", fontsize=18, y=1.02)
plt.show()

mejor_modelo = resultados_df.index[0]
print(f"\n Mejor modelo: {mejor_modelo}")

matriz = resultados[mejor_modelo]['Matriz de Confusión']
plt.figure(figsize=(6, 4))
sns.heatmap(matriz, annot=True, fmt='d', cmap='Blues')
plt.title(f"Matriz de Confusión - {mejor_modelo}")
plt.xlabel('Predicción')
plt.ylabel('Real')
plt.show()

"""Comparativa de metricas claves en todos los modelos

Detectar presencia de enfermedad cardíaca (Clase 1), por lo que métricas como Recall, F1-score, y Precision para la Clase 1 son clave. Es más grave no detectar una enfermedad (falso negativo) que tener una falsa alarma (falso positivo).

- Recall (Sensibilidad) es crítica → mide cuántos casos positivos reales detectó correctamente.

- F1-score combina Precision y Recall → útil cuando hay un desequilibrio o el costo de error es alto.

Tiene el mejor Recall (1.0): no deja pasar ningún paciente enfermo.

### 6. Poner a punto (fine-tune) esos modelos y si es posible combinarlos en una gran solución.

#### Reentrenamiento con Cross-Validation
- Aplicamos validación cruzada estratificada para asegurar estabilidad del resultado:
"""

from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.naive_bayes import GaussianNB
import numpy as np

# Modelo
nb_model = GaussianNB()

# Validación cruzada estratificada
cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)
scores = cross_val_score(nb_model, X_train, y_train, scoring='recall', cv=cv)

# Resultados
print("Recall promedio (Clase 1):", np.mean(scores))
print("Desviación estándar:", np.std(scores))

"""Ajustar el umbral de clasificación, útil cuando nos interesa priorizar recall en lugar de precisión"""

from sklearn.metrics import recall_score

# Entrenar modelo
nb_model.fit(X_train, y_train)

# Predecir probabilidades
y_probs = nb_model.predict_proba(X_test)[:,1]

# Ajustar el umbral
umbral = 0.3
y_pred_adjusted = (y_probs > umbral).astype(int)

# Evaluar
print("Recall ajustado:", recall_score(y_test, y_pred_adjusted))

"""Al mantener el modelo “ajustado” de Naive Bayes mantuvo el mismo recall (1.0)

Matriz de Confusión del Modelo Ajustado

El ajuste de hiperparámetros no hizo que el modelo empeorara.

- Para GaussianNB no hay muchos hiperparámetros para ajustar.

- Aun haciendo validación cruzada o refinamientos, el modelo siguió clasificando correctamente todos los casos positivos → no hubo falsos negativos.

- Esto indica que el modelo Naive Bayes está funcionando “idealmente” para esta métrica.
"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

conf_matrix = confusion_matrix(y_test, y_pred_adjusted)
ConfusionMatrixDisplay(confusion_matrix=conf_matrix).plot(cmap='Oranges')

"""### 7. Presentar la solución, ¿Cual es la mejor solución?

#### **¿Por qué Gaussian Naive Bayes?**
El modelo Gaussian Naive Bayes resultó ser el mejor en este caso por varias razones:

- Rendimiento en Recall: Obtuvo un valor de Recall igual a 1.0 en la clase positiva (pacientes con enfermedad cardíaca), es decir, detectó correctamente a todos los enfermos en el conjunto de prueba.
Esto lo convierte en el modelo más confiable desde un punto de vista clínico y ético.

- Simplicidad y eficiencia: Es un modelo muy eficiente para problemas con muchas variables numéricas y supuestos de distribución normal, lo cual se ajusta al tipo de datos que tenemos (como presión arterial, colesterol, frecuencia cardíaca, etc.).

- Generalización con pocos datos: Naive Bayes funciona bien incluso en conjuntos de datos de tamaño reducido y evita el sobreajuste, lo que lo hace ideal para nuestro caso.

- Interpretabilidad: Los modelos Naive Bayes son más fáciles de interpretar y auditar, una característica clave en contextos médicos y de salud pública.

#### **¿Por qué la métrica de evaluación principal es Recall?**

Esto se debe a que:

- Un falso negativo (es decir, predecir que un paciente NO tiene enfermedad cardíaca cuando realmente SÍ la tiene) puede tener consecuencias graves o incluso fatales.

- En cambio, un falso positivo (diagnosticar incorrectamente como enfermo a un paciente sano) puede generar ansiedad y costos innecesarios, pero no compromete la vida directamente.

Por lo tanto, **preferimos un modelo que tenga una alta capacidad de detectar correctamente a los pacientes con enfermedad cardíaca**, aunque ocasionalmente dé falsos positivos.

## **2. MLP Classifier**
"""

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""Entrenamiento"""

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

mlp = MLPClassifier(
    hidden_layer_sizes=(100, 50),   # 2 capas ocultas
    activation='relu',
    solver='adam',
    max_iter=300,
    random_state=42,
    early_stopping=True,
    verbose=True
)
mlp.fit(X_train_scaled, y_train)

"""Evaluación del modelo"""

y_pred = mlp.predict(X_test_scaled)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Reporte de clasificación:")
print(classification_report(y_test, y_pred))

# Matriz de confusión
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')
plt.title("Matriz de confusión")
plt.xlabel("Predicción")
plt.ylabel("Real")
plt.show()

""" Búsqueda de hiperparámetros"""

param_grid = {
    'hidden_layer_sizes': [(50,), (100,), (100, 50)],
    'activation': ['relu', 'tanh'],
    'alpha': [0.0001, 0.001],
    'learning_rate_init': [0.001, 0.01],
    'max_iter': [300]

}

grid = GridSearchCV(MLPClassifier(random_state=42, early_stopping=True), param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)
grid.fit(X_train_scaled, y_train)

print("Mejores parámetros:", grid.best_params_)

best_model = grid.best_estimator_
y_pred_best = best_model.predict(X_test_scaled)
print("Accuracy del mejor modelo:", accuracy_score(y_test, y_pred_best))
print(classification_report(y_test, y_pred_best))

plt.plot(mlp.loss_curve_)
plt.title("Curva de pérdida durante el entrenamiento")
plt.xlabel("Época")
plt.ylabel("Pérdida")
plt.grid(True)
plt.show()

